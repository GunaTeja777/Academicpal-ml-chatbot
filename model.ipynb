{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pd.read_csv(r'C:\\Users\\tejag\\OneDrive\\Desktop\\A chat bot\\Academicpal-ml-chatbot\\model\\Academicpal chatbot1styear - Sheet1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semester</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Notes Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st</td>\n",
       "      <td>Physics</td>\n",
       "      <td>New Physics</td>\n",
       "      <td>physics, science, mechanics</td>\n",
       "      <td>https://drive.google.com/drive/folders/1e-LQMg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Problem Solving</td>\n",
       "      <td>problem solving, psp, logic</td>\n",
       "      <td>https://drive.google.com/drive/u/5/folders/1yK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Maths</td>\n",
       "      <td>math, maths, calculus, algebra</td>\n",
       "      <td>https://drive.google.com/drive/folders/1sYdBua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Basic Electronics</td>\n",
       "      <td>electronics, basic electronics, circuits</td>\n",
       "      <td>https://drive.google.com/drive/folders/17iJtHY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Cyber Security</td>\n",
       "      <td>cyber security, security, hacking</td>\n",
       "      <td>https://drive.google.com/drive/folders/17kg_R1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Semester    Cycle            Subject  \\\n",
       "0      1st  Physics        New Physics   \n",
       "1      1st  Physics    Problem Solving   \n",
       "2      1st  Physics              Maths   \n",
       "3      1st  Physics  Basic Electronics   \n",
       "4      1st  Physics     Cyber Security   \n",
       "\n",
       "                                   Keywords  \\\n",
       "0               physics, science, mechanics   \n",
       "1               problem solving, psp, logic   \n",
       "2            math, maths, calculus, algebra   \n",
       "3  electronics, basic electronics, circuits   \n",
       "4         cyber security, security, hacking   \n",
       "\n",
       "                                          Notes Link  \n",
       "0  https://drive.google.com/drive/folders/1e-LQMg...  \n",
       "1  https://drive.google.com/drive/u/5/folders/1yK...  \n",
       "2  https://drive.google.com/drive/folders/1sYdBua...  \n",
       "3  https://drive.google.com/drive/folders/17iJtHY...  \n",
       "4  https://drive.google.com/drive/folders/17kg_R1...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semester      0\n",
       "Cycle         0\n",
       "Subject       0\n",
       "Keywords      0\n",
       "Notes Link    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semester\n",
       "1st    20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[\"Semester\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: click in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk fuzzywuzzy pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tejag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tejag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Download NLTK data (only needed once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = \"Academicpal chatbot1styear - Sheet1.csv\"  # Update with actual path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert to lowercase for better matching\n",
    "df[\"Subject\"] = df[\"Subject\"].str.lower()\n",
    "df[\"Cycle\"] = df[\"Cycle\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"Academicpal chatbot1styear - Sheet1.csv\"  # Update with actual path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert to lowercase for better matching\n",
    "df[\"Subject\"] = df[\"Subject\"].str.lower()\n",
    "df[\"Cycle\"] = df[\"Cycle\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize & lowercase\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cycles: ['physics' 'chemistry']\n",
      "Here is the link to your maths (physics) notes: https://drive.google.com/drive/folders/1sYdBua6wr7uhMYw4uIKw5hrPtYd10c_B\n"
     ]
    }
   ],
   "source": [
    "def get_notes(df):\n",
    "    user_input = input(\"What notes do you need? \")  # Example: \"I want maths notes\"\n",
    "    processed_input = preprocess_input(user_input)  \n",
    "\n",
    "    # Use fuzzy matching to find the best subject\n",
    "    subject_list = df[\"Subject\"].unique()\n",
    "    best_match, score = process.extractOne(processed_input, subject_list)\n",
    "\n",
    "    if score < 50:  # If confidence is low\n",
    "        print(\"No relevant subject found. Please try again.\")\n",
    "        return\n",
    "\n",
    "    # Filter subjects that match\n",
    "    matched_subjects = df[df[\"Subject\"] == best_match]\n",
    "\n",
    "    # Check if multiple cycles exist\n",
    "    unique_cycles = matched_subjects[\"Cycle\"].unique()\n",
    "\n",
    "    if len(unique_cycles) > 1:\n",
    "        print(\"Available cycles:\", unique_cycles)\n",
    "        cycle = input(\"Enter the cycle: \").strip().lower()\n",
    "\n",
    "        # Filter by cycle\n",
    "        matched_subjects = matched_subjects[matched_subjects[\"Cycle\"] == cycle]\n",
    "\n",
    "    # Get the notes link\n",
    "    if not matched_subjects.empty:\n",
    "        link = matched_subjects[\"Notes Link\"].values[0]\n",
    "        print(f\"Here is the link to your {best_match} ({cycle}) notes: {link}\")\n",
    "    else:\n",
    "        print(\"No notes found for the given subject and cycle.\")\n",
    "get_notes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tejag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\tejag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tejag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.6.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pyspellchecker in c:\\users\\tejag\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.8.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "2025-02-27 09:42:59,424 - INFO - Best parameters found: {'clf__max_depth': None, 'clf__n_estimators': 10, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 1)}\n",
      "2025-02-27 09:42:59,425 - INFO - Best cross-validation score: 0.125\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-02-27 09:42:59,440 - INFO - Classification Report:\n",
      "                                                                              precision    recall  f1-score   support\n",
      "\n",
      "    https://drive.google.com/drive/folders/11qYDOnYNVIRyVNSYOFan64n-RHn8ozIa       0.00      0.00      0.00         1\n",
      "    https://drive.google.com/drive/folders/11s9sgR-Hpb40p2tVlsetlBWcE6UPIubO       0.00      0.00      0.00         0\n",
      "    https://drive.google.com/drive/folders/16T2_I_JIEisswgPj4Xk6S_OY_DTtCklG       0.00      0.00      0.00         1\n",
      "    https://drive.google.com/drive/folders/17lhdfYPpJruKzbPyIbqv2wL9TBdvwgDq       0.00      0.00      0.00         0\n",
      "    https://drive.google.com/drive/folders/1e-LQMg0B7XF9wJDfWg4vWwc8SZg16LXt       0.00      0.00      0.00         1\n",
      "https://drive.google.com/drive/u/5/folders/1yKkXdRkNXuui8Ysq7hCygAPak9OS49O_       1.00      1.00      1.00         1\n",
      "\n",
      "                                                                    accuracy                           0.25         4\n",
      "                                                                   macro avg       0.17      0.17      0.17         4\n",
      "                                                                weighted avg       0.25      0.25      0.25         4\n",
      "\n",
      "2025-02-27 09:42:59,728 - INFO - Corrected query: i want math notes from physics cycle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best matching notes link: https://drive.google.com/drive/folders/1sYdBua6wr7uhMYw4uIKw5hrPtYd10c_B\n"
     ]
    }
   ],
   "source": [
    "%pip install textdistance\n",
    "%pip install pyspellchecker\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from spellchecker import SpellChecker\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def correct_spelling(query, keywords):\n",
    "    spell = SpellChecker()\n",
    "    # Add domain-specific terms to the spell checker\n",
    "    spell.word_frequency.load_words(keywords)\n",
    "    words = query.lower().split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        if word in spell:\n",
    "            corrected_words.append(word)\n",
    "        else:\n",
    "            # Find the closest match in keywords\n",
    "            closest_match = min(keywords, key=lambda k: levenshtein.distance(word, k))\n",
    "            corrected_words.append(closest_match)\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def load_data():\n",
    "    data = pd.read_csv(r'C:\\Users\\tejag\\OneDrive\\Desktop\\A chat bot\\Academicpal-ml-chatbot\\model\\Academicpal chatbot1styear - Sheet1.csv')\n",
    "    # Validate data\n",
    "    if data.isnull().any().any():\n",
    "        logging.warning(\"Missing values found in the dataset. Filling with empty strings.\")\n",
    "        data = data.fillna('')\n",
    "    return data\n",
    "\n",
    "def train_model(data):\n",
    "    # Combine relevant columns into a single text column\n",
    "    data['Text'] = data['Cycle'] + \" \" + data['Subject'] + \" \" + data['Keywords']\n",
    "    X = data['Text']\n",
    "    y = data['Notes Link']\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(lowercase=True, stop_words='english')),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Define hyperparameters for grid search\n",
    "    parameters = {\n",
    "        'tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "        'clf__n_estimators': [10, 50, 100],\n",
    "        'clf__max_depth': [None, 10, 20],\n",
    "    }\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=2, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Log best parameters and score\n",
    "    logging.info(\"Best parameters found: %s\", grid_search.best_params_)\n",
    "    logging.info(\"Best cross-validation score: %s\", grid_search.best_score_)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    logging.info(\"Classification Report:\\n%s\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save the vectorizer and model separately\n",
    "    vectorizer = grid_search.best_estimator_.named_steps['tfidf']\n",
    "    model = grid_search.best_estimator_.named_steps['clf']\n",
    "    \n",
    "    with open(\"vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
    "        pickle.dump(vectorizer, vectorizer_file)\n",
    "    \n",
    "    with open(\"model.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "    \n",
    "    # Save keywords\n",
    "    with open(\"keywords.pkl\", \"wb\") as keywords_file:\n",
    "        pickle.dump(data['Keywords'].str.split(', ').explode().unique(), keywords_file)\n",
    "\n",
    "def find_notes(query):\n",
    "    try:\n",
    "        if not query.strip():\n",
    "            logging.warning(\"Empty query provided.\")\n",
    "            return None\n",
    "        \n",
    "        # Load vectorizer, model, and keywords\n",
    "        with open(\"vectorizer.pkl\", \"rb\") as vectorizer_file:\n",
    "            vectorizer = pickle.load(vectorizer_file)\n",
    "        \n",
    "        with open(\"model.pkl\", \"rb\") as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "        \n",
    "        with open(\"keywords.pkl\", \"rb\") as keywords_file:\n",
    "            keywords = pickle.load(keywords_file)\n",
    "        \n",
    "        # Correct spelling\n",
    "        corrected_query = correct_spelling(query, keywords)\n",
    "        logging.info(\"Corrected query: %s\", corrected_query)\n",
    "        \n",
    "        # Transform the query using the vectorizer\n",
    "        query_vector = vectorizer.transform([corrected_query])\n",
    "        \n",
    "        # Predict the notes link\n",
    "        prediction = model.predict(query_vector)[0]\n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred: %s\", e)\n",
    "        return None\n",
    "\n",
    "# Load dataset\n",
    "data = load_data()\n",
    "train_model(data)\n",
    "\n",
    "# Example query\n",
    "query = \"I want mathz notes from phyzics cycle\"\n",
    "notes_link = find_notes(query)\n",
    "if notes_link:\n",
    "    print(\"Best matching notes link:\", notes_link)\n",
    "else:\n",
    "    print(\"Failed to find notes link.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 09:44:46,049 - INFO - Corrected query: i want math notes from physics cycle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best matching notes link: https://drive.google.com/drive/folders/1sYdBua6wr7uhMYw4uIKw5hrPtYd10c_B\n"
     ]
    }
   ],
   "source": [
    "query = \"I want mathz notes from phyzics cycle\"\n",
    "notes_link = find_notes(query)\n",
    "if notes_link:\n",
    "    print(\"Best matching notes link:\", notes_link)\n",
    "else:\n",
    "    print(\"Failed to find notes link.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "2025-02-27 10:22:50,848 - INFO - Best parameters found: {'clf__max_depth': None, 'clf__n_estimators': 10, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 1)}\n",
      "2025-02-27 10:22:50,849 - INFO - Best cross-validation score: 0.125\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\tejag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-02-27 10:22:50,888 - INFO - Classification Report:\n",
      "                                                                              precision    recall  f1-score   support\n",
      "\n",
      "    https://drive.google.com/drive/folders/11qYDOnYNVIRyVNSYOFan64n-RHn8ozIa       0.00      0.00      0.00         1\n",
      "    https://drive.google.com/drive/folders/11s9sgR-Hpb40p2tVlsetlBWcE6UPIubO       0.00      0.00      0.00         0\n",
      "    https://drive.google.com/drive/folders/16T2_I_JIEisswgPj4Xk6S_OY_DTtCklG       0.00      0.00      0.00         1\n",
      "    https://drive.google.com/drive/folders/17lhdfYPpJruKzbPyIbqv2wL9TBdvwgDq       0.00      0.00      0.00         0\n",
      "    https://drive.google.com/drive/folders/1e-LQMg0B7XF9wJDfWg4vWwc8SZg16LXt       0.00      0.00      0.00         1\n",
      "https://drive.google.com/drive/u/5/folders/1yKkXdRkNXuui8Ysq7hCygAPak9OS49O_       1.00      1.00      1.00         1\n",
      "\n",
      "                                                                    accuracy                           0.25         4\n",
      "                                                                   macro avg       0.17      0.17      0.17         4\n",
      "                                                                weighted avg       0.25      0.25      0.25         4\n",
      "\n",
      "2025-02-27 10:22:51,148 - INFO - Corrected query: i want math notes from physics cycle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best matching notes link: https://drive.google.com/drive/folders/1sYdBua6wr7uhMYw4uIKw5hrPtYd10c_B\n"
     ]
    }
   ],
   "source": [
    "# Modified model training code\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from spellchecker import SpellChecker\n",
    "import textdistance\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def correct_spelling(query, keywords):\n",
    "    spell = SpellChecker()\n",
    "    # Add domain-specific terms to the spell checker\n",
    "    spell.word_frequency.load_words(keywords)\n",
    "    words = query.lower().split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        if word in spell:\n",
    "            corrected_words.append(word)\n",
    "        else:\n",
    "            # Use a safer approach to find closest match\n",
    "            min_distance = float('inf')\n",
    "            closest_word = word  # Default to original word\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                try:\n",
    "                    distance = textdistance.levenshtein.distance(word, keyword)\n",
    "                    # Handle case where distance might be an array\n",
    "                    if isinstance(distance, (list, np.ndarray)):\n",
    "                        distance = float(distance[0]) if len(distance) > 0 else float('inf')\n",
    "                    \n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        closest_word = keyword\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error calculating distance: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            corrected_words.append(closest_word)\n",
    "            \n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def load_data():\n",
    "    data = pd.read_csv(r'C:\\Users\\tejag\\OneDrive\\Desktop\\A chat bot\\Academicpal-ml-chatbot\\Academicpal chatbot1styear - Sheet1.csv')\n",
    "    # Validate data\n",
    "    if data.isnull().any().any():\n",
    "        logging.warning(\"Missing values found in the dataset. Filling with empty strings.\")\n",
    "        data = data.fillna('')\n",
    "    return data\n",
    "\n",
    "def train_model(data):\n",
    "    # Combine relevant columns into a single text column\n",
    "    data['Text'] = data['Cycle'] + \" \" + data['Subject'] + \" \" + data['Keywords']\n",
    "    X = data['Text']\n",
    "    y = data['Notes Link']\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(lowercase=True, stop_words='english')),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Define hyperparameters for grid search\n",
    "    parameters = {\n",
    "        'tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "        'clf__n_estimators': [10, 50, 100],\n",
    "        'clf__max_depth': [None, 10, 20],\n",
    "    }\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=2, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Log best parameters and score\n",
    "    logging.info(\"Best parameters found: %s\", grid_search.best_params_)\n",
    "    logging.info(\"Best cross-validation score: %s\", grid_search.best_score_)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    logging.info(\"Classification Report:\\n%s\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save the vectorizer and model separately\n",
    "    vectorizer = grid_search.best_estimator_.named_steps['tfidf']\n",
    "    model = grid_search.best_estimator_.named_steps['clf']\n",
    "    \n",
    "    with open(\"vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
    "        pickle.dump(vectorizer, vectorizer_file)\n",
    "    \n",
    "    with open(\"model.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "    \n",
    "    # Save keywords - make sure they're plain strings, not numpy arrays or other complex types\n",
    "    keywords_list = data['Keywords'].str.split(', ').explode().unique().tolist()\n",
    "    with open(\"keywords.pkl\", \"wb\") as keywords_file:\n",
    "        pickle.dump(keywords_list, keywords_file)\n",
    "\n",
    "def find_notes(query):\n",
    "    try:\n",
    "        if not query.strip():\n",
    "            logging.warning(\"Empty query provided.\")\n",
    "            return None\n",
    "        \n",
    "        # Load vectorizer, model, and keywords\n",
    "        with open(\"vectorizer.pkl\", \"rb\") as vectorizer_file:\n",
    "            vectorizer = pickle.load(vectorizer_file)\n",
    "        \n",
    "        with open(\"model.pkl\", \"rb\") as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "        \n",
    "        with open(\"keywords.pkl\", \"rb\") as keywords_file:\n",
    "            keywords = pickle.load(keywords_file)\n",
    "        \n",
    "        # Correct spelling\n",
    "        corrected_query = correct_spelling(query, keywords)\n",
    "        logging.info(\"Corrected query: %s\", corrected_query)\n",
    "        \n",
    "        # Transform the query using the vectorizer\n",
    "        query_vector = vectorizer.transform([corrected_query])\n",
    "        \n",
    "        # Predict the notes link\n",
    "        prediction = model.predict(query_vector)[0]\n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        logging.error(\"An error occurred: %s\", e)\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset\n",
    "    data = load_data()\n",
    "    train_model(data)\n",
    "\n",
    "    # Example query\n",
    "    query = \"I want mathz notes from phyzics cycle\"\n",
    "    notes_link = find_notes(query)\n",
    "    if notes_link:\n",
    "        print(\"Best matching notes link:\", notes_link)\n",
    "    else:\n",
    "        print(\"Failed to find notes link.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
